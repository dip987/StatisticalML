{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Pipeline Example\n",
    "This notebook contains sample code on how to use the data-processing pipeline  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Starting up anything, we need to add the folder containing all the source code to Jupyter Notebooks\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"\\\\project_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once added, we can call all our project functions without any issues\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "# from project_code.missingdata import DataImputer\n",
    "from encoding import DataEncoder\n",
    "from missingdata import DataImputer\n",
    "from exploration_helper_functions import load_data\n",
    "\n",
    "# Load up the data\n",
    "data_path = Path(r'data/netflix_data.csv')\n",
    "df = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up the default Imputer\n",
    "imputer = DataImputer()\n",
    "imputer.fit_transform(df)\n",
    "\n",
    "# Set-up the default Encoder\n",
    "encoder = DataEncoder()\n",
    "x, y = encoder.fit_transform(dataframe=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is (13379, 175)\n",
      "The shape of X is (13379,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of X is {x.shape}\")\n",
    "print(f\"The shape of X is {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the feature vector X and the result variable y using the default fits. The default settings are different for each column.\n",
    "\n",
    "Now if we want to customize the imputer/encoder, we can pass in a column name and a MissingDataHandler object/BaseEncoding object mapping into the Imputer/Encoder during initantiation. A small example is given below.\n",
    "\n",
    "The Data contains a Genre column. If we want, we can impute the genre column the most frequenct values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from missingdata import ReplaceWithHighestFrequency\n",
    "\n",
    "df = load_data(data_path)\n",
    "custom_column_imputer = ReplaceWithHighestFrequency()\n",
    "imputer = DataImputer(scheme={'Genre' : custom_column_imputer})\n",
    "imputer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also assume for this Genre column, we want to only keep the top 10 most common genres. If an entry has one or multiple of the most frequent genres we only keep those and place a 1.0 for each of them and drop the rest. If for example, an entry does not contain any of them top genres, we will label encode it with all zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoding import KeepTopN\n",
    "\n",
    "custom_column_encoder = KeepTopN(N = 10)\n",
    "encoder = DataEncoder(scheme={'Genre' : custom_column_encoder})\n",
    "x, y = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Family',\n",
       " 'Fantasy',\n",
       " 'Animation',\n",
       " 'Adventure',\n",
       " 'Crime',\n",
       " 'Romance',\n",
       " 'Thriller',\n",
       " 'Action',\n",
       " 'Comedy',\n",
       " 'Drama']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_column_encoder.category_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top-10 categories as determined by the encoder.(With the momst occuring one starting out from the bottom, in this case 'Drama' \n",
    "\n",
    "After trying out simple regression algorithms, XGBoost usually gave the best results.(Without delving into perceptrons). So for most of the project, different data imputation and encoding schemes are measured using XGBoost. The code in the cells below demonstrate the evaluation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "from method_evaluation import evaluate_model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=42, n_estimators=120)\n",
    "mean, var = evaluate_model(model, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.014 and Variance: 0.00007\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean: {mean:,.3f} and Variance: {var:,.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluate_model function applies 5-fold cross-validation(by default) and returns mean and the variace for the test error(MSE for this project). From these two values, we can get a good understanding of how well the model performs. We want a low mean as a as a low varaince. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
